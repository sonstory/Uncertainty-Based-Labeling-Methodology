{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc47430d",
   "metadata": {},
   "source": [
    "# Uncertainty Based Cost-Effective Labeling Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8858bc",
   "metadata": {},
   "source": [
    "# Device Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ffd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab7da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_setting:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc7d5a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94721dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=9, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ef3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetParameters(model, train_dl, valid_dl):\n",
    "    device = gpu_setting.device\n",
    "    model = model.lower()\n",
    "    if model == 'resnet34':\n",
    "        model = resnet34().to(device)\n",
    "    if model == 'resnet50':\n",
    "        model = resnet50().to(device)\n",
    "    if model == 'resnet101':\n",
    "        model = resnet101().to(device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "    \n",
    "    # definc the training parameters\n",
    "    params_train = {\n",
    "        'num_epochs':5,\n",
    "        'optimizer':opt,\n",
    "        'loss_func':loss_func,\n",
    "        'train_dl':train_dl, \n",
    "        'val_dl':valid_dl,\n",
    "        'sanity_check':False,\n",
    "        'lr_scheduler':lr_scheduler,\n",
    "        'path2weights':'./trained_model/weights_original_res.pt'\n",
    "    }\n",
    "    return model, params_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c57c7",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "def train_val(model, params, epoch):\n",
    "    num_epochs=epoch\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f0a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet():\n",
    "    def __init__(self, main_dir, transform, num):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.num = num\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f484b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSubset(Dataset):\n",
    "    def __init__(self,Subset,transform=None):\n",
    "        super(CustomSubset,self).__init__()\n",
    "        self.Subset=Subset\n",
    "        self.indices=Subset.indices\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Subset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img,label=self.Subset[idx]\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc13659",
   "metadata": {},
   "source": [
    "# csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb095259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_155655 = pd.read_csv('../csv/data_155655.csv')\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb49d96",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84403059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b993947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial train data(17,295)\n",
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60047b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13836 3459\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "714b7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f16799d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c82bb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.331893, val loss: 0.324012, accuracy: 90.78, time: 1.5423 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.228293, val loss: 0.287123, accuracy: 92.74, time: 2.4251 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.206911, val loss: 0.194008, accuracy: 94.68, time: 3.2917 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.183145, val loss: 0.187804, accuracy: 94.28, time: 4.1291 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.175342, val loss: 0.223950, accuracy: 94.02, time: 4.9915 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253a5a5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba7077",
   "metadata": {},
   "source": [
    "### Set 1 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "779a54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c373b21",
   "metadata": {},
   "source": [
    "### Set 1 data predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e00f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "579b812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3076a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810a532",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fc98f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72da18",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb2764f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3517285.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineer_label_count = []\n",
    "wrong_cnt_list = []\n",
    "real_label_list = list(df_155655.loc[:17294]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb742030",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59df7a7",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "897cfae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509]\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42d33d",
   "metadata": {},
   "source": [
    "## Append Set 1 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d655de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e23b78",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc020a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34babf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "96bff746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27672 6918\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "683601dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e93ffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e2b7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.345949, val loss: 0.447560, accuracy: 87.14, time: 1.6770 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.205498, val loss: 0.185279, accuracy: 94.81, time: 3.4603 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "train loss: 0.168548, val loss: 0.189313, accuracy: 95.09, time: 5.1698 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.145948, val loss: 0.264448, accuracy: 92.09, time: 6.8366 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.128392, val loss: 0.115933, accuracy: 96.14, time: 8.5057 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df4418",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fada1",
   "metadata": {},
   "source": [
    "### Set 2 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf5d25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "91bbb596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dff395",
   "metadata": {},
   "source": [
    "### Set 2 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b69fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bb5d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b45e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bcb7f",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e0ece346",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fe391",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "76133f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 4338286.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*1:17295*2-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "787d4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a4bec",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea0f6229",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673]\n",
      "[4, 91]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300937c0",
   "metadata": {},
   "source": [
    "## Append Set 2 Data to Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "305474b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626030f",
   "metadata": {},
   "source": [
    "# Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bbc79",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce2eef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70496597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41508 10377\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5a1223db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f05dcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d418a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.347857, val loss: 1.300647, accuracy: 84.41, time: 2.7268 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.207475, val loss: 0.245724, accuracy: 92.56, time: 5.3616 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.169871, val loss: 0.158580, accuracy: 95.01, time: 8.0267 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.143709, val loss: 0.134284, accuracy: 95.62, time: 10.6906 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.128882, val loss: 0.130549, accuracy: 95.78, time: 13.3967 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f2920",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5063921",
   "metadata": {},
   "source": [
    "### Set 3 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e28fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "390a3906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3463439",
   "metadata": {},
   "source": [
    "### Set 3 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58af0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e034eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a443db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12766a9e",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6dd9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5f62a",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a8b4aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3470670.67it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*2:17295*3-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "951ece9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafeed49",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "68a26d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969]\n",
      "[4, 91, 16]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc56204",
   "metadata": {},
   "source": [
    "## Append Set 3 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17703ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d71d1f",
   "metadata": {},
   "source": [
    "# Phase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a636e9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3008d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6cef9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55344 13836\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "75b51cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7b7cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "71774200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.298132, val loss: 0.221231, accuracy: 92.14, time: 3.4211 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.182382, val loss: 0.187300, accuracy: 94.13, time: 6.8321 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.151660, val loss: 0.166604, accuracy: 94.65, time: 10.3746 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.131734, val loss: 0.173981, accuracy: 95.24, time: 13.8325 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.117286, val loss: 0.109345, accuracy: 96.31, time: 17.2106 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fded5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e72e27",
   "metadata": {},
   "source": [
    "### Set 4 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5812e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "22282948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf469d",
   "metadata": {},
   "source": [
    "### Set 4  Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "eba38c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9b31e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3602316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d05f6",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f67d2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd50df2",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "77b217da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 4338286.45it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*3:17295*4-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "23a5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425768c",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f50425bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457]\n",
      "[4, 91, 16, 13]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68511d95",
   "metadata": {},
   "source": [
    "## Append Set 4 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0da2e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31b2f",
   "metadata": {},
   "source": [
    "# Phase 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0b4fb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "45c791c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6dfd2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69180 17295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c5ec60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dbf0f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f104f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.257689, val loss: 0.671637, accuracy: 80.55, time: 4.2218 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.162191, val loss: 0.155870, accuracy: 94.81, time: 8.7474 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.133412, val loss: 0.136975, accuracy: 95.77, time: 12.8994 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.116397, val loss: 0.106244, accuracy: 96.82, time: 17.1054 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.101641, val loss: 0.100716, accuracy: 96.87, time: 21.3612 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da80ac",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf669f",
   "metadata": {},
   "source": [
    "### Set 5 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "89bf891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec196ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90dcac",
   "metadata": {},
   "source": [
    "### Set 5 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2b662194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2315a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "759a44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88601ef7",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e69863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287d536",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a9e4791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 4267087.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*4:17295*5-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b842c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac424516",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7cb79110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457, 1292]\n",
      "[4, 91, 16, 13, 76]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81d9a1",
   "metadata": {},
   "source": [
    "## Append Set 5 to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cc060d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf453024",
   "metadata": {},
   "source": [
    "# Phase 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872a0b7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7c833e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "88750564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83016 20754\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1a28a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "37993798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "208f70dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.230613, val loss: 0.290637, accuracy: 93.92, time: 5.0159 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.146696, val loss: 0.124405, accuracy: 96.01, time: 10.2698 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "train loss: 0.120556, val loss: 0.126586, accuracy: 95.96, time: 15.3039 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.102748, val loss: 0.091183, accuracy: 96.85, time: 20.3808 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.088343, val loss: 0.102171, accuracy: 96.64, time: 25.4856 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a8ae8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89384f",
   "metadata": {},
   "source": [
    "### Set 6 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a87c18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8fe80841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a507e",
   "metadata": {},
   "source": [
    "### Set 6 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f865ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c6125408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "70f11204",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d66b12",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d2f06ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818dc4b",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c186b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3471168.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*5:17295*6-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c48c0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee012fb7",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "057f6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457, 1292, 3624]\n",
      "[4, 91, 16, 13, 76, 6]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca9c31",
   "metadata": {},
   "source": [
    "## Appned Set 6 Data to Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b3d1c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b8dc5",
   "metadata": {},
   "source": [
    "# Phase 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401221aa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "45a11ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "615a8646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96852 24213\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ac6e38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4f930a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfcbec21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.220039, val loss: 0.143973, accuracy: 95.25, time: 5.9654 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.138641, val loss: 0.142830, accuracy: 95.94, time: 11.9636 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.113925, val loss: 0.098353, accuracy: 96.77, time: 17.6082 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.098396, val loss: 0.102648, accuracy: 96.69, time: 23.2945 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.085633, val loss: 0.105934, accuracy: 96.95, time: 29.2065 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2d17b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de130196",
   "metadata": {},
   "source": [
    "### Set 7 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "af490315",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50577300",
   "metadata": {},
   "source": [
    "### Set 7 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "00b3ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e6f6a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f015",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4d92e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fe7ea1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 4339064.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*6:17295*7-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "31af1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf00145",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5bacc46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457, 1292, 3624, 2707]\n",
      "[4, 91, 16, 13, 76, 6, 89]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a910aee",
   "metadata": {},
   "source": [
    "## Append Set 7 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f2647f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32734c9",
   "metadata": {},
   "source": [
    "# Phase 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f5c4f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "8063d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2cb6c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110688 27672\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2763e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ed21319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ad416be3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.218783, val loss: 0.120962, accuracy: 96.02, time: 6.8736 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "train loss: 0.137047, val loss: 0.180607, accuracy: 94.15, time: 13.5853 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.114426, val loss: 0.101990, accuracy: 96.78, time: 20.2777 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.097166, val loss: 0.085713, accuracy: 97.13, time: 27.1191 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.085197, val loss: 0.086822, accuracy: 97.22, time: 33.6976 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c7fc0",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b72b4a",
   "metadata": {},
   "source": [
    "### Set 8 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "af29d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fb076",
   "metadata": {},
   "source": [
    "### Set 8 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "bb8708cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cb9e6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf71cc",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e10cf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5b980",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "75018c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2479169.09it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*7:17295*8-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eff48fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51584ae6",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "20f03228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457, 1292, 3624, 2707, 2407]\n",
      "[4, 91, 16, 13, 76, 6, 89, 42]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4ab6d",
   "metadata": {},
   "source": [
    "## Add Set 8 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3a6a89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975304c",
   "metadata": {},
   "source": [
    "# Phase 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d70ac5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b54a6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bc3d2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124524 31131\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6ead8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "eb25ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3a17dc7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.195456, val loss: 0.173200, accuracy: 94.39, time: 7.9019 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.129623, val loss: 0.123411, accuracy: 95.87, time: 15.5351 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.105067, val loss: 0.111319, accuracy: 96.59, time: 22.8452 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.089976, val loss: 0.086758, accuracy: 97.23, time: 30.0729 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.077460, val loss: 0.083575, accuracy: 97.18, time: 37.3162 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba512ca2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90189f",
   "metadata": {},
   "source": [
    "### Set 9 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "83117b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bfb75",
   "metadata": {},
   "source": [
    "### Set 9 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "af7d754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8352085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1434ea",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1b4c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa18aa",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "b4b8a4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3431595.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*8:17295*9-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a0d3d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009150cb",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "af3be60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9509, 5673, 3969, 4457, 1292, 3624, 2707, 2407, 5218]\n",
      "[4, 91, 16, 13, 76, 6, 89, 42, 9]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6e1da",
   "metadata": {},
   "source": [
    "## Add Set 9 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "86d04d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a65db",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- Mislabelings : 346 / 155,655(0.22%)\n",
    "    - per phase : 4 / 91 / 16 / 13 / 76 / 6 / 89 / 42 / 9\n",
    "- Engineer Cost : 38,856 / 155,655(25.00%)\n",
    "    - per phase : 9,509 / 5,673 / 3,969 / 4,457 / 1,292 / 3,624 / 2,707 / 2,407 / 5,218"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "408px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
