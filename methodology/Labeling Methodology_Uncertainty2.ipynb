{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aee12e6",
   "metadata": {},
   "source": [
    "# Uncertainty Based Labeling Methodology\n",
    "- Uncertainty 2 : Least Margin\n",
    "- Model : ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7df33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4ed4b",
   "metadata": {},
   "source": [
    "# Device Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11892c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2202466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_setting:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3790d726",
   "metadata": {},
   "source": [
    "# Model(ResNet50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9031be",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cff6f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=9, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d87c36",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "437a2c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetParameters(model, train_dl, valid_dl):\n",
    "    device = gpu_setting.device\n",
    "    model = model.lower()\n",
    "    if model == 'resnet34':\n",
    "        model = resnet34().to(device)\n",
    "    if model == 'resnet50':\n",
    "        model = resnet50().to(device)\n",
    "    if model == 'resnet101':\n",
    "        model = resnet101().to(device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "    \n",
    "    # definc the training parameters\n",
    "    params_train = {\n",
    "        'num_epochs':5,\n",
    "        'optimizer':opt,\n",
    "        'loss_func':loss_func,\n",
    "        'train_dl':train_dl, \n",
    "        'val_dl':valid_dl,\n",
    "        'sanity_check':False,\n",
    "        'lr_scheduler':lr_scheduler,\n",
    "        'path2weights':'./trained_model/weights_original_res.pt', #이거 변경해서 사용\n",
    "    }\n",
    "    return model, params_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a4ae68",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be47b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "def train_val(model, params, epoch):\n",
    "    num_epochs=epoch\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e99f1e",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94346c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet():\n",
    "    def __init__(self, main_dir, transform, num):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.num = num\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17a70ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count = []\n",
    "wrong_cnt_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5282dfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_155655 = pd.read_csv('../csv/data_155655.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c288ed9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155655, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_155655.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d868bf5",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e00413f",
   "metadata": {},
   "source": [
    "### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0acf7e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6d75227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "48ad55e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19fd5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b4d4d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "778b8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "172486be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.344339, val loss: 0.505448, accuracy: 87.68, time: 3.9003 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.221236, val loss: 0.290321, accuracy: 92.15, time: 5.5265 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.205943, val loss: 0.277957, accuracy: 92.14, time: 7.1047 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.175019, val loss: 0.400956, accuracy: 86.86, time: 8.6751 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.166867, val loss: 0.265863, accuracy: 91.22, time: 10.2692 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8041608",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "795a96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeb585bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8adc739",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8690e512",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15d2411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*0:17295*1-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a2afb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2479084.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "248a8777",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd81dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839]\n",
      "[44]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d045223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3eabc7",
   "metadata": {},
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13725166",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec75fc38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 34590\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "de5045c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66259672",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6811ad82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd554320",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52012fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.317448, val loss: 0.438243, accuracy: 86.58, time: 4.0013 min\n",
      "----------\n",
      "Epoch 1/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.191020, val loss: 0.347640, accuracy: 89.30, time: 6.5525 min\n",
      "----------\n",
      "Epoch 2/6, current lr=0.001\n",
      "train loss: 0.152808, val loss: 0.580875, accuracy: 86.22, time: 8.9706 min\n",
      "----------\n",
      "Epoch 3/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.137607, val loss: 0.294596, accuracy: 90.44, time: 11.2738 min\n",
      "----------\n",
      "Epoch 4/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.127160, val loss: 0.249808, accuracy: 91.46, time: 13.6026 min\n",
      "----------\n",
      "Epoch 5/6, current lr=0.001\n",
      "train loss: 0.110110, val loss: 0.297326, accuracy: 90.62, time: 15.9595 min\n",
      "----------\n",
      "Epoch 6/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.099325, val loss: 0.214200, accuracy: 93.07, time: 18.4612 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5435c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87844a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d22f0482",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6eff2cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02604044",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54e3874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*1:17295*2-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93e48c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2478999.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b10a752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d72f97b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423]\n",
      "[44, 53]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "080ad0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493584ab",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22358687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "487bfc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 51885\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e4556ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e9fc0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3263eedb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81b2a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6b6e0918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.318775, val loss: 0.180838, accuracy: 95.17, time: 3.8731 min\n",
      "----------\n",
      "Epoch 1/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.194050, val loss: 0.135126, accuracy: 95.60, time: 7.2562 min\n",
      "----------\n",
      "Epoch 2/8, current lr=0.001\n",
      "train loss: 0.161656, val loss: 0.144084, accuracy: 95.50, time: 10.6268 min\n",
      "----------\n",
      "Epoch 3/8, current lr=0.001\n",
      "train loss: 0.140839, val loss: 0.144980, accuracy: 96.19, time: 14.0310 min\n",
      "----------\n",
      "Epoch 4/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.119237, val loss: 0.131449, accuracy: 96.22, time: 17.4627 min\n",
      "----------\n",
      "Epoch 5/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.104939, val loss: 0.116134, accuracy: 96.66, time: 20.8698 min\n",
      "----------\n",
      "Epoch 6/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.090749, val loss: 0.113959, accuracy: 96.54, time: 24.3026 min\n",
      "----------\n",
      "Epoch 7/8, current lr=0.001\n",
      "train loss: 0.079747, val loss: 0.138694, accuracy: 96.43, time: 27.8129 min\n",
      "----------\n",
      "Epoch 8/8, current lr=0.001\n",
      "train loss: 0.069977, val loss: 0.149556, accuracy: 96.65, time: 31.2804 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ecef1a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5748bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2d803512",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9883fa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "65d8ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00175678",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*2:17295*3-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1aab0d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2479253.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6f73f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4fee0589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305]\n",
      "[44, 53, 148]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9e625d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e913399",
   "metadata": {},
   "source": [
    "### Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "39dfddb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "38a69c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 69180\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e064da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8814b3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "170eed98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3dcd1759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0f4df23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.271770, val loss: 0.185292, accuracy: 94.85, time: 4.3832 min\n",
      "----------\n",
      "Epoch 1/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.165723, val loss: 0.063778, accuracy: 98.10, time: 8.9465 min\n",
      "----------\n",
      "Epoch 2/10, current lr=0.001\n",
      "train loss: 0.136450, val loss: 0.096489, accuracy: 97.40, time: 13.7088 min\n",
      "----------\n",
      "Epoch 3/10, current lr=0.001\n",
      "train loss: 0.117684, val loss: 0.090777, accuracy: 97.31, time: 18.6062 min\n",
      "----------\n",
      "Epoch 4/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.100418, val loss: 0.051193, accuracy: 98.51, time: 22.9458 min\n",
      "----------\n",
      "Epoch 5/10, current lr=0.001\n",
      "train loss: 0.089916, val loss: 0.054008, accuracy: 98.51, time: 27.3228 min\n",
      "----------\n",
      "Epoch 6/10, current lr=0.001\n",
      "train loss: 0.079049, val loss: 0.062908, accuracy: 98.22, time: 31.6674 min\n",
      "----------\n",
      "Epoch 7/10, current lr=0.001\n",
      "train loss: 0.070326, val loss: 0.054013, accuracy: 98.42, time: 35.9547 min\n",
      "----------\n",
      "Epoch 8/10, current lr=0.001\n",
      "train loss: 0.060587, val loss: 0.051903, accuracy: 98.53, time: 40.0999 min\n",
      "----------\n",
      "Epoch 9/10, current lr=0.001\n",
      "train loss: 0.054323, val loss: 0.059077, accuracy: 98.50, time: 44.1875 min\n",
      "----------\n",
      "Epoch 10/10, current lr=0.001\n",
      "train loss: 0.046075, val loss: 0.072222, accuracy: 97.84, time: 48.3535 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8932eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e54f426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "beb0fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e78240c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ccdf1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f55a23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*3:17295*4-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c8f0d243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892363.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0655fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bfc76c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325]\n",
      "[44, 53, 148, 35]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d653196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0568f526",
   "metadata": {},
   "source": [
    "###  Phase 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5caf6885",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "25f229dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 86475\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2a5ab936",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "26d93e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b3d69c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "45a43537",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a16bde9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.233020, val loss: 0.118947, accuracy: 96.85, time: 5.0767 min\n",
      "----------\n",
      "Epoch 1/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.143368, val loss: 0.096510, accuracy: 97.06, time: 10.1035 min\n",
      "----------\n",
      "Epoch 2/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.120339, val loss: 0.086390, accuracy: 97.62, time: 15.3713 min\n",
      "----------\n",
      "Epoch 3/12, current lr=0.001\n",
      "train loss: 0.102939, val loss: 0.119251, accuracy: 97.09, time: 20.5951 min\n",
      "----------\n",
      "Epoch 4/12, current lr=0.001\n",
      "train loss: 0.090331, val loss: 0.104038, accuracy: 97.39, time: 25.8755 min\n",
      "----------\n",
      "Epoch 5/12, current lr=0.001\n",
      "train loss: 0.077687, val loss: 0.097925, accuracy: 97.54, time: 31.3380 min\n",
      "----------\n",
      "Epoch 6/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.070241, val loss: 0.080663, accuracy: 97.77, time: 36.4658 min\n",
      "----------\n",
      "Epoch 7/12, current lr=0.001\n",
      "train loss: 0.061344, val loss: 0.107725, accuracy: 97.54, time: 41.3920 min\n",
      "----------\n",
      "Epoch 8/12, current lr=0.001\n",
      "train loss: 0.053853, val loss: 0.095517, accuracy: 97.74, time: 46.3223 min\n",
      "----------\n",
      "Epoch 9/12, current lr=0.001\n",
      "train loss: 0.047162, val loss: 0.092331, accuracy: 97.72, time: 51.2588 min\n",
      "----------\n",
      "Epoch 10/12, current lr=0.001\n",
      "train loss: 0.042598, val loss: 0.114208, accuracy: 97.62, time: 56.4527 min\n",
      "----------\n",
      "Epoch 11/12, current lr=0.001\n",
      "train loss: 0.036499, val loss: 0.130738, accuracy: 97.65, time: 61.5545 min\n",
      "----------\n",
      "Epoch 12/12, current lr=0.001\n",
      "train loss: 0.032195, val loss: 0.118967, accuracy: 97.66, time: 66.5913 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "cc5ba119",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "448eb3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93759d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c6dc3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "969b40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b646ff75",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*4:17295*5-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cd0cf447",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2478999.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4db44245",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8f437ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325, 839]\n",
      "[44, 53, 148, 35, 128]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5bcfd7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee5a39e",
   "metadata": {},
   "source": [
    "### Phase 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "49013f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e9108324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 103770\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "44194326",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "29d18f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f67fd84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e86f329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95c75978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.211947, val loss: 0.105341, accuracy: 96.84, time: 5.9088 min\n",
      "----------\n",
      "Epoch 1/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.132811, val loss: 0.094891, accuracy: 97.17, time: 15.5801 min\n",
      "----------\n",
      "Epoch 2/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.108700, val loss: 0.085866, accuracy: 97.54, time: 23.5696 min\n",
      "----------\n",
      "Epoch 3/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.091785, val loss: 0.080731, accuracy: 97.86, time: 29.9129 min\n",
      "----------\n",
      "Epoch 4/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.077703, val loss: 0.070102, accuracy: 97.83, time: 35.9348 min\n",
      "----------\n",
      "Epoch 5/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.067913, val loss: 0.063139, accuracy: 98.07, time: 41.7385 min\n",
      "----------\n",
      "Epoch 6/14, current lr=0.001\n",
      "train loss: 0.059906, val loss: 0.081834, accuracy: 97.69, time: 47.5457 min\n",
      "----------\n",
      "Epoch 7/14, current lr=0.001\n",
      "train loss: 0.053524, val loss: 0.071774, accuracy: 97.71, time: 53.3831 min\n",
      "----------\n",
      "Epoch 8/14, current lr=0.001\n",
      "train loss: 0.047585, val loss: 0.067234, accuracy: 97.93, time: 59.1916 min\n",
      "----------\n",
      "Epoch 9/14, current lr=0.001\n",
      "train loss: 0.040470, val loss: 0.069381, accuracy: 97.73, time: 64.9717 min\n",
      "----------\n",
      "Epoch 10/14, current lr=0.001\n",
      "train loss: 0.035669, val loss: 0.068221, accuracy: 97.83, time: 70.7664 min\n",
      "----------\n",
      "Epoch 11/14, current lr=0.001\n",
      "train loss: 0.030131, val loss: 0.083508, accuracy: 98.01, time: 76.5499 min\n",
      "----------\n",
      "Epoch 12/14, current lr=0.001\n",
      "train loss: 0.026440, val loss: 0.072248, accuracy: 97.98, time: 82.3258 min\n",
      "----------\n",
      "Epoch 13/14, current lr=0.001\n",
      "train loss: 0.023185, val loss: 0.086157, accuracy: 97.95, time: 88.1226 min\n",
      "----------\n",
      "Epoch 14/14, current lr=0.001\n",
      "train loss: 0.019832, val loss: 0.095380, accuracy: 97.94, time: 93.9147 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7523c421",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e24d2d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "de03e64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "641f81f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "2270f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "47b51d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*5:17295*6-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4abe6cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2479084.37it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "99cd77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e0c61a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325, 839, 868]\n",
      "[44, 53, 148, 35, 128, 98]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c69ac8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96181d45",
   "metadata": {},
   "source": [
    "### Phase 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ee9f5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2bada62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 121065\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cd3d7b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "30f72ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "88430409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "2cded9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81f9ee14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.198689, val loss: 0.181273, accuracy: 94.57, time: 7.3541 min\n",
      "----------\n",
      "Epoch 1/16, current lr=0.001\n",
      "train loss: 0.124463, val loss: 0.190708, accuracy: 94.54, time: 14.0413 min\n",
      "----------\n",
      "Epoch 2/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.101433, val loss: 0.162898, accuracy: 94.91, time: 21.1244 min\n",
      "----------\n",
      "Epoch 3/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.086382, val loss: 0.126553, accuracy: 95.69, time: 28.1433 min\n",
      "----------\n",
      "Epoch 4/16, current lr=0.001\n",
      "train loss: 0.073492, val loss: 0.140117, accuracy: 95.57, time: 34.9194 min\n",
      "----------\n",
      "Epoch 5/16, current lr=0.001\n",
      "train loss: 0.063774, val loss: 0.144440, accuracy: 95.22, time: 42.2558 min\n",
      "----------\n",
      "Epoch 6/16, current lr=0.001\n",
      "train loss: 0.056675, val loss: 0.154556, accuracy: 95.77, time: 49.1299 min\n",
      "----------\n",
      "Epoch 7/16, current lr=0.001\n",
      "train loss: 0.050274, val loss: 0.142693, accuracy: 95.96, time: 55.9648 min\n",
      "----------\n",
      "Epoch 8/16, current lr=0.001\n",
      "train loss: 0.043258, val loss: 0.148639, accuracy: 95.41, time: 63.2139 min\n",
      "----------\n",
      "Epoch 9/16, current lr=0.001\n",
      "train loss: 0.038488, val loss: 0.167217, accuracy: 94.78, time: 69.9960 min\n",
      "----------\n",
      "Epoch 10/16, current lr=0.001\n",
      "train loss: 0.033016, val loss: 0.166257, accuracy: 94.87, time: 76.6150 min\n",
      "----------\n",
      "Epoch 11/16, current lr=0.001\n",
      "train loss: 0.028058, val loss: 0.159289, accuracy: 95.80, time: 83.2516 min\n",
      "----------\n",
      "Epoch 12/16, current lr=0.001\n",
      "train loss: 0.024438, val loss: 0.164938, accuracy: 94.74, time: 89.8732 min\n",
      "----------\n",
      "Epoch 13/16, current lr=0.001\n",
      "train loss: 0.021120, val loss: 0.210877, accuracy: 95.43, time: 96.4964 min\n",
      "----------\n",
      "Epoch 14/16, current lr=0.001\n",
      "train loss: 0.018951, val loss: 0.206710, accuracy: 95.63, time: 103.1266 min\n",
      "----------\n",
      "Epoch 15/16, current lr=0.0001\n",
      "train loss: 0.005357, val loss: 0.193505, accuracy: 96.11, time: 109.8264 min\n",
      "----------\n",
      "Epoch 16/16, current lr=0.0001\n",
      "train loss: 0.002708, val loss: 0.217160, accuracy: 96.10, time: 116.4553 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "5029af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5faa911e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b6f73346",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8656f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "726d0827",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b9ab1801",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*6:17295*7-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7575ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892248.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "1e6639ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e1f81393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325, 839, 868, 1220]\n",
      "[44, 53, 148, 35, 128, 98, 240]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "38ec6ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c6918",
   "metadata": {},
   "source": [
    "### Phase 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a85e7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "904b6ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 138360\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b4bd9330",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "180a3a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "54a90571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "686114ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3adcc55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.189066, val loss: 0.108915, accuracy: 97.17, time: 8.3022 min\n",
      "----------\n",
      "Epoch 1/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.119554, val loss: 0.079677, accuracy: 97.66, time: 16.1214 min\n",
      "----------\n",
      "Epoch 2/18, current lr=0.001\n",
      "train loss: 0.095237, val loss: 0.080740, accuracy: 97.91, time: 23.5240 min\n",
      "----------\n",
      "Epoch 3/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.079484, val loss: 0.061188, accuracy: 98.05, time: 31.5035 min\n",
      "----------\n",
      "Epoch 4/18, current lr=0.001\n",
      "train loss: 0.069462, val loss: 0.074445, accuracy: 97.79, time: 39.7060 min\n",
      "----------\n",
      "Epoch 5/18, current lr=0.001\n",
      "train loss: 0.061647, val loss: 0.069349, accuracy: 97.80, time: 47.4637 min\n",
      "----------\n",
      "Epoch 6/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.053223, val loss: 0.056571, accuracy: 98.31, time: 54.9693 min\n",
      "----------\n",
      "Epoch 7/18, current lr=0.001\n",
      "train loss: 0.047175, val loss: 0.060807, accuracy: 98.20, time: 62.4750 min\n",
      "----------\n",
      "Epoch 8/18, current lr=0.001\n",
      "train loss: 0.042114, val loss: 0.102616, accuracy: 96.90, time: 69.9654 min\n",
      "----------\n",
      "Epoch 9/18, current lr=0.001\n",
      "train loss: 0.035819, val loss: 0.063332, accuracy: 98.23, time: 77.4465 min\n",
      "----------\n",
      "Epoch 10/18, current lr=0.001\n",
      "train loss: 0.030922, val loss: 0.069739, accuracy: 98.06, time: 84.9376 min\n",
      "----------\n",
      "Epoch 11/18, current lr=0.001\n",
      "train loss: 0.026770, val loss: 0.073012, accuracy: 98.15, time: 92.4277 min\n",
      "----------\n",
      "Epoch 12/18, current lr=0.001\n",
      "train loss: 0.022754, val loss: 0.080685, accuracy: 98.24, time: 99.9188 min\n",
      "----------\n",
      "Epoch 13/18, current lr=0.001\n",
      "train loss: 0.019941, val loss: 0.078502, accuracy: 98.18, time: 107.4193 min\n",
      "----------\n",
      "Epoch 14/18, current lr=0.001\n",
      "train loss: 0.017802, val loss: 0.089563, accuracy: 98.18, time: 114.9688 min\n",
      "----------\n",
      "Epoch 15/18, current lr=0.001\n",
      "train loss: 0.016630, val loss: 0.099966, accuracy: 98.18, time: 122.2380 min\n",
      "----------\n",
      "Epoch 16/18, current lr=0.001\n",
      "train loss: 0.013996, val loss: 0.095155, accuracy: 97.96, time: 129.0423 min\n",
      "----------\n",
      "Epoch 17/18, current lr=0.001\n",
      "train loss: 0.012349, val loss: 0.100420, accuracy: 98.21, time: 136.5362 min\n",
      "----------\n",
      "Epoch 18/18, current lr=0.0001\n",
      "train loss: 0.003858, val loss: 0.093764, accuracy: 98.32, time: 144.0287 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "8aab4f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3f378ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b7604d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a9f746c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "51a7a2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3fa0013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*7:17295*8-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "46b38859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2479338.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "64da6c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f4e118a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325, 839, 868, 1220, 569]\n",
      "[44, 53, 148, 35, 128, 98, 240, 100]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "77bf2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fe1842",
   "metadata": {},
   "source": [
    "### Phase 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "681651e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1bc6fe00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 155655\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f30e3672",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d5c6c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e0718c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c2726fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "84c966b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.180848, val loss: 0.124646, accuracy: 96.10, time: 9.2071 min\n",
      "----------\n",
      "Epoch 1/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.112200, val loss: 0.103022, accuracy: 96.73, time: 17.7909 min\n",
      "----------\n",
      "Epoch 2/20, current lr=0.001\n",
      "train loss: 0.090029, val loss: 0.119757, accuracy: 96.55, time: 26.7230 min\n",
      "----------\n",
      "Epoch 3/20, current lr=0.001\n",
      "train loss: 0.075896, val loss: 0.111839, accuracy: 96.28, time: 35.7249 min\n",
      "----------\n",
      "Epoch 4/20, current lr=0.001\n",
      "train loss: 0.066329, val loss: 0.121576, accuracy: 96.36, time: 44.2725 min\n",
      "----------\n",
      "Epoch 5/20, current lr=0.001\n",
      "train loss: 0.057530, val loss: 0.105744, accuracy: 96.80, time: 53.3541 min\n",
      "----------\n",
      "Epoch 6/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.051797, val loss: 0.091022, accuracy: 97.10, time: 61.7009 min\n",
      "----------\n",
      "Epoch 7/20, current lr=0.001\n",
      "train loss: 0.045762, val loss: 0.140473, accuracy: 96.44, time: 70.1499 min\n",
      "----------\n",
      "Epoch 8/20, current lr=0.001\n",
      "train loss: 0.040404, val loss: 0.107059, accuracy: 96.63, time: 78.5848 min\n",
      "----------\n",
      "Epoch 9/20, current lr=0.001\n",
      "train loss: 0.035417, val loss: 0.114018, accuracy: 96.81, time: 87.5075 min\n",
      "----------\n",
      "Epoch 10/20, current lr=0.001\n",
      "train loss: 0.030953, val loss: 0.105464, accuracy: 96.92, time: 96.0334 min\n",
      "----------\n",
      "Epoch 11/20, current lr=0.001\n",
      "train loss: 0.026342, val loss: 0.113629, accuracy: 96.84, time: 104.3706 min\n",
      "----------\n",
      "Epoch 12/20, current lr=0.001\n",
      "train loss: 0.022816, val loss: 0.113166, accuracy: 96.80, time: 112.7139 min\n",
      "----------\n",
      "Epoch 13/20, current lr=0.001\n",
      "train loss: 0.019215, val loss: 0.135959, accuracy: 96.84, time: 121.0351 min\n",
      "----------\n",
      "Epoch 14/20, current lr=0.001\n",
      "train loss: 0.017167, val loss: 0.153552, accuracy: 96.91, time: 129.3692 min\n",
      "----------\n",
      "Epoch 15/20, current lr=0.001\n",
      "train loss: 0.015652, val loss: 0.141744, accuracy: 97.07, time: 137.6950 min\n",
      "----------\n",
      "Epoch 16/20, current lr=0.001\n",
      "train loss: 0.013763, val loss: 0.138584, accuracy: 96.73, time: 146.0121 min\n",
      "----------\n",
      "Epoch 17/20, current lr=0.001\n",
      "train loss: 0.012815, val loss: 0.143651, accuracy: 96.80, time: 154.3400 min\n",
      "----------\n",
      "Epoch 18/20, current lr=0.0001\n",
      "train loss: 0.003399, val loss: 0.147861, accuracy: 97.16, time: 162.6764 min\n",
      "----------\n",
      "Epoch 19/20, current lr=0.0001\n",
      "train loss: 0.001613, val loss: 0.183245, accuracy: 96.94, time: 171.0154 min\n",
      "----------\n",
      "Epoch 20/20, current lr=0.0001\n",
      "train loss: 0.001253, val loss: 0.171072, accuracy: 97.01, time: 179.3685 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "43249de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e773b0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "e0c685ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2a80b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "31bae7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if bool(pred_list[i][0].sort().values[-1] - pred_list[i][0].sort().values[-2] <= 0.98):\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "959a03c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*8:17295*9-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "326caa22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2478914.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "02f574d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdac4809",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c9a93aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5839, 4423, 1305, 2325, 839, 868, 1220, 569, 799]\n",
      "[44, 53, 148, 35, 128, 98, 240, 100, 182]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "14d4292c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
