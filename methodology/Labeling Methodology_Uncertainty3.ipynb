{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674f518b",
   "metadata": {},
   "source": [
    "# Uncertainty Based Labeling Methodology\n",
    "- Uncertainty 3 : Entropy\n",
    "- Model : ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a622da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de83dec0",
   "metadata": {},
   "source": [
    "# Device Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f651e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bafda34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_setting:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b656306",
   "metadata": {},
   "source": [
    "# Model(ResNet50)\n",
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3675ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # BatchNorm에 bias가 포함되어 있으므로, conv2d는 bias=False로 설정~~ 홍용민 메롱~~\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=9, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bae8ea4",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2872f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetParameters(model, train_dl, valid_dl):\n",
    "    device = gpu_setting.device\n",
    "    model = model.lower()\n",
    "    if model == 'resnet34':\n",
    "        model = resnet34().to(device)\n",
    "    if model == 'resnet50':\n",
    "        model = resnet50().to(device)\n",
    "    if model == 'resnet101':\n",
    "        model = resnet101().to(device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "    \n",
    "    # definc the training parameters\n",
    "    params_train = {\n",
    "        'num_epochs':5,\n",
    "        'optimizer':opt,\n",
    "        'loss_func':loss_func,\n",
    "        'train_dl':train_dl, \n",
    "        'val_dl':valid_dl,\n",
    "        'sanity_check':False,\n",
    "        'lr_scheduler':lr_scheduler,\n",
    "        'path2weights':'./trained_model/weights_original_res.pt', #이거 변경해서 사용\n",
    "    }\n",
    "    return model, params_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda8ad8a",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70a20c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "def train_val(model, params, epoch):\n",
    "    num_epochs=epoch\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e91d30",
   "metadata": {},
   "source": [
    "# CustomDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7fbdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet():\n",
    "    def __init__(self, main_dir, transform, num):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.num = num\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "481d8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count = []\n",
    "wrong_cnt_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889df157",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_155655 = pd.read_csv('../csv/data_155655.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b589a374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(155655, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_155655.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9edd19",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7726f62d",
   "metadata": {},
   "source": [
    "### Phase 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fb7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fe6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aa5f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18afba98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bcbc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc73b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.365695, val loss: 0.464802, accuracy: 84.50, time: 3.7675 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "train loss: 0.237779, val loss: 1.221917, accuracy: 70.38, time: 6.0740 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.205691, val loss: 0.268737, accuracy: 91.29, time: 8.3698 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.181101, val loss: 0.299791, accuracy: 90.90, time: 10.6455 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.168214, val loss: 0.374037, accuracy: 89.40, time: 12.8911 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "851aaf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63cabfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01ed5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "671c293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7571242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[:17294]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c38c35ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2658134.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "86cf3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4f1da1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454]\n",
      "[71]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ef589513",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295 ):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7032b6a",
   "metadata": {},
   "source": [
    "### Phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f71d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "db759ef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 34590\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a887f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9c4cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "283d56ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63840708",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4357947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.336242, val loss: 0.472596, accuracy: 86.71, time: 5.0681 min\n",
      "----------\n",
      "Epoch 1/6, current lr=0.001\n",
      "train loss: 0.199856, val loss: 0.519107, accuracy: 83.24, time: 8.9200 min\n",
      "----------\n",
      "Epoch 2/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.161001, val loss: 0.347463, accuracy: 88.57, time: 12.7410 min\n",
      "----------\n",
      "Epoch 3/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.141628, val loss: 0.308766, accuracy: 90.73, time: 16.5635 min\n",
      "----------\n",
      "Epoch 4/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.129363, val loss: 0.212458, accuracy: 92.67, time: 20.3954 min\n",
      "----------\n",
      "Epoch 5/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.118252, val loss: 0.194507, accuracy: 93.36, time: 24.2190 min\n",
      "----------\n",
      "Epoch 6/6, current lr=0.001\n",
      "train loss: 0.108663, val loss: 0.230824, accuracy: 92.50, time: 28.0570 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d1193fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bc97425a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c1371352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54ff77dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1e6a4847",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9303fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*1:17295*2-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0eb9afea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3140008.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "734e9530",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "640ac2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932]\n",
      "[71, 29]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "719d247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05f105",
   "metadata": {},
   "source": [
    "### Phase 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ef17c84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f9156c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 51885\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b53048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c90922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "397ca628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "91f05566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ce28949c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.306321, val loss: 0.164376, accuracy: 95.47, time: 6.7564 min\n",
      "----------\n",
      "Epoch 1/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.192399, val loss: 0.147278, accuracy: 95.91, time: 14.3437 min\n",
      "----------\n",
      "Epoch 2/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.155962, val loss: 0.137225, accuracy: 96.20, time: 19.7461 min\n",
      "----------\n",
      "Epoch 3/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.135220, val loss: 0.120691, accuracy: 95.89, time: 25.1177 min\n",
      "----------\n",
      "Epoch 4/8, current lr=0.001\n",
      "train loss: 0.115513, val loss: 0.149405, accuracy: 94.64, time: 30.5073 min\n",
      "----------\n",
      "Epoch 5/8, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.100391, val loss: 0.103206, accuracy: 96.84, time: 35.8943 min\n",
      "----------\n",
      "Epoch 6/8, current lr=0.001\n",
      "train loss: 0.087955, val loss: 0.107645, accuracy: 96.68, time: 41.2701 min\n",
      "----------\n",
      "Epoch 7/8, current lr=0.001\n",
      "train loss: 0.077808, val loss: 0.109517, accuracy: 96.62, time: 46.6787 min\n",
      "----------\n",
      "Epoch 8/8, current lr=0.001\n",
      "train loss: 0.067421, val loss: 0.119024, accuracy: 96.62, time: 52.1268 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d66ccffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2f5bb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b33be6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "51a7a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d7f2efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1a04f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*2:17295*3-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "2e48aa88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2881563.82it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "99f1379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a6a63c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204]\n",
      "[71, 29, 54]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cfc32cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7595b88",
   "metadata": {},
   "source": [
    "### Phase 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ea577cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6e7a2701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 69180\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1868f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c28f52d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78b161a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f645fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8057629f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.274004, val loss: 0.093508, accuracy: 97.81, time: 8.3381 min\n",
      "----------\n",
      "Epoch 1/10, current lr=0.001\n",
      "train loss: 0.167522, val loss: 0.468085, accuracy: 86.05, time: 15.3074 min\n",
      "----------\n",
      "Epoch 2/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.135751, val loss: 0.058293, accuracy: 98.28, time: 22.2529 min\n",
      "----------\n",
      "Epoch 3/10, current lr=0.001\n",
      "train loss: 0.116412, val loss: 0.103176, accuracy: 97.27, time: 29.2373 min\n",
      "----------\n",
      "Epoch 4/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.097726, val loss: 0.048199, accuracy: 98.45, time: 36.2107 min\n",
      "----------\n",
      "Epoch 5/10, current lr=0.001\n",
      "train loss: 0.089625, val loss: 0.050624, accuracy: 98.47, time: 43.1759 min\n",
      "----------\n",
      "Epoch 6/10, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.079335, val loss: 0.043360, accuracy: 98.70, time: 50.1408 min\n",
      "----------\n",
      "Epoch 7/10, current lr=0.001\n",
      "train loss: 0.067710, val loss: 0.045896, accuracy: 98.69, time: 57.0924 min\n",
      "----------\n",
      "Epoch 8/10, current lr=0.001\n",
      "train loss: 0.062671, val loss: 0.046876, accuracy: 98.47, time: 64.0781 min\n",
      "----------\n",
      "Epoch 9/10, current lr=0.001\n",
      "train loss: 0.053928, val loss: 0.048724, accuracy: 98.55, time: 71.0548 min\n",
      "----------\n",
      "Epoch 10/10, current lr=0.001\n",
      "train loss: 0.047755, val loss: 0.044353, accuracy: 98.75, time: 78.0256 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fb89fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6336d518",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5a55981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5066197e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "64ff1a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*3:17295*4-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "11369df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2882250.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e52050c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "271cfa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236]\n",
      "[71, 29, 54, 22]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5f0253c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b20a9a8",
   "metadata": {},
   "source": [
    "### Phase 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fde3e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7df85070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 86475\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9d8296f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14b90a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a8091bea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "760c3bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "39e54116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.247128, val loss: 0.113029, accuracy: 96.94, time: 9.6733 min\n",
      "----------\n",
      "Epoch 1/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.153352, val loss: 0.103355, accuracy: 96.93, time: 18.1372 min\n",
      "----------\n",
      "Epoch 2/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.121920, val loss: 0.095832, accuracy: 97.29, time: 26.6207 min\n",
      "----------\n",
      "Epoch 3/12, current lr=0.001\n",
      "train loss: 0.103342, val loss: 0.101988, accuracy: 97.35, time: 35.1477 min\n",
      "----------\n",
      "Epoch 4/12, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.090971, val loss: 0.083641, accuracy: 97.48, time: 43.6649 min\n",
      "----------\n",
      "Epoch 5/12, current lr=0.001\n",
      "train loss: 0.079304, val loss: 0.094295, accuracy: 97.27, time: 52.2009 min\n",
      "----------\n",
      "Epoch 6/12, current lr=0.001\n",
      "train loss: 0.071245, val loss: 0.092398, accuracy: 97.61, time: 60.7267 min\n",
      "----------\n",
      "Epoch 7/12, current lr=0.001\n",
      "train loss: 0.062879, val loss: 0.123837, accuracy: 97.24, time: 69.2660 min\n",
      "----------\n",
      "Epoch 8/12, current lr=0.001\n",
      "train loss: 0.055902, val loss: 0.089766, accuracy: 97.55, time: 77.7966 min\n",
      "----------\n",
      "Epoch 9/12, current lr=0.001\n",
      "train loss: 0.049083, val loss: 0.106330, accuracy: 97.61, time: 86.3080 min\n",
      "----------\n",
      "Epoch 10/12, current lr=0.001\n",
      "train loss: 0.042732, val loss: 0.102712, accuracy: 97.71, time: 94.8352 min\n",
      "----------\n",
      "Epoch 11/12, current lr=0.001\n",
      "train loss: 0.036050, val loss: 0.107254, accuracy: 97.71, time: 103.3773 min\n",
      "----------\n",
      "Epoch 12/12, current lr=0.001\n",
      "train loss: 0.032580, val loss: 0.100326, accuracy: 97.79, time: 111.9335 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3f7869ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "756a5b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "23f16221",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "21a39258",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "3b94fa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*4:17295*5-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "098b8747",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2658329.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f02dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "394c0187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236, 1007]\n",
      "[71, 29, 54, 22, 87]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "41c9befc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c7f23d",
   "metadata": {},
   "source": [
    "### Phase 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d7f71b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5f31e597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 103770\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1206383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "17c269ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2297d75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0000719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "50a43a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.216744, val loss: 0.143736, accuracy: 96.12, time: 11.2195 min\n",
      "----------\n",
      "Epoch 1/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.135173, val loss: 0.111585, accuracy: 96.79, time: 21.1979 min\n",
      "----------\n",
      "Epoch 2/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.107634, val loss: 0.089172, accuracy: 97.36, time: 31.2359 min\n",
      "----------\n",
      "Epoch 3/14, current lr=0.001\n",
      "train loss: 0.089437, val loss: 0.099070, accuracy: 97.05, time: 41.2689 min\n",
      "----------\n",
      "Epoch 4/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.077979, val loss: 0.059651, accuracy: 97.88, time: 51.3123 min\n",
      "----------\n",
      "Epoch 5/14, current lr=0.001\n",
      "train loss: 0.069275, val loss: 0.069212, accuracy: 97.68, time: 61.4210 min\n",
      "----------\n",
      "Epoch 6/14, current lr=0.001\n",
      "train loss: 0.061727, val loss: 0.071138, accuracy: 97.62, time: 71.5034 min\n",
      "----------\n",
      "Epoch 7/14, current lr=0.001\n",
      "train loss: 0.054209, val loss: 0.062512, accuracy: 97.83, time: 81.5818 min\n",
      "----------\n",
      "Epoch 8/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.048340, val loss: 0.059031, accuracy: 98.20, time: 91.7806 min\n",
      "----------\n",
      "Epoch 9/14, current lr=0.001\n",
      "train loss: 0.040715, val loss: 0.061632, accuracy: 97.96, time: 104.4777 min\n",
      "----------\n",
      "Epoch 10/14, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.036442, val loss: 0.058397, accuracy: 98.18, time: 114.5115 min\n",
      "----------\n",
      "Epoch 11/14, current lr=0.001\n",
      "train loss: 0.030981, val loss: 0.064073, accuracy: 98.01, time: 124.5631 min\n",
      "----------\n",
      "Epoch 12/14, current lr=0.001\n",
      "train loss: 0.027754, val loss: 0.067274, accuracy: 98.16, time: 134.6573 min\n",
      "----------\n",
      "Epoch 13/14, current lr=0.001\n",
      "train loss: 0.023204, val loss: 0.075057, accuracy: 98.13, time: 144.7519 min\n",
      "----------\n",
      "Epoch 14/14, current lr=0.001\n",
      "train loss: 0.021777, val loss: 0.076219, accuracy: 97.91, time: 154.8429 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a9ae18d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f2098bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "43621fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "831ce7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "13224094",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*5:17295*6-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fa78dfbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2720846.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "07ad0c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "11e1b44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236, 1007, 1152]\n",
      "[71, 29, 54, 22, 87, 37]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9e448918",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea185b1",
   "metadata": {},
   "source": [
    "### Phase 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "fa33f4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "db577710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 121065\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "dfdd7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "87e92478",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "858bc269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "89cc128d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1d811eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.206134, val loss: 0.323298, accuracy: 91.27, time: 12.7954 min\n",
      "----------\n",
      "Epoch 1/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.128309, val loss: 0.168751, accuracy: 94.82, time: 24.2973 min\n",
      "----------\n",
      "Epoch 2/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.104690, val loss: 0.137902, accuracy: 95.44, time: 35.9319 min\n",
      "----------\n",
      "Epoch 3/16, current lr=0.001\n",
      "train loss: 0.089232, val loss: 0.139714, accuracy: 95.18, time: 47.5904 min\n",
      "----------\n",
      "Epoch 4/16, current lr=0.001\n",
      "train loss: 0.075160, val loss: 0.154688, accuracy: 95.26, time: 59.2202 min\n",
      "----------\n",
      "Epoch 5/16, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.065473, val loss: 0.135465, accuracy: 95.42, time: 70.8596 min\n",
      "----------\n",
      "Epoch 6/16, current lr=0.001\n",
      "train loss: 0.058044, val loss: 0.137603, accuracy: 95.52, time: 82.4733 min\n",
      "----------\n",
      "Epoch 7/16, current lr=0.001\n",
      "train loss: 0.051300, val loss: 0.143514, accuracy: 95.49, time: 94.1313 min\n",
      "----------\n",
      "Epoch 8/16, current lr=0.001\n",
      "train loss: 0.045372, val loss: 0.137121, accuracy: 95.92, time: 105.7885 min\n",
      "----------\n",
      "Epoch 9/16, current lr=0.001\n",
      "train loss: 0.039568, val loss: 0.151309, accuracy: 95.85, time: 117.4387 min\n",
      "----------\n",
      "Epoch 10/16, current lr=0.001\n",
      "train loss: 0.033507, val loss: 0.147475, accuracy: 95.92, time: 129.0705 min\n",
      "----------\n",
      "Epoch 11/16, current lr=0.001\n",
      "train loss: 0.029582, val loss: 0.146445, accuracy: 95.84, time: 140.7039 min\n",
      "----------\n",
      "Epoch 12/16, current lr=0.001\n",
      "train loss: 0.025055, val loss: 0.194364, accuracy: 95.70, time: 152.3013 min\n",
      "----------\n",
      "Epoch 13/16, current lr=0.001\n",
      "train loss: 0.022492, val loss: 0.196310, accuracy: 95.78, time: 163.9416 min\n",
      "----------\n",
      "Epoch 14/16, current lr=0.001\n",
      "train loss: 0.018989, val loss: 0.196965, accuracy: 95.84, time: 175.5734 min\n",
      "----------\n",
      "Epoch 15/16, current lr=0.001\n",
      "train loss: 0.016806, val loss: 0.184227, accuracy: 95.75, time: 187.2045 min\n",
      "----------\n",
      "Epoch 16/16, current lr=0.001\n",
      "train loss: 0.015665, val loss: 0.172719, accuracy: 95.66, time: 198.8235 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6a8b8b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b369d1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e393ae10",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "95b523e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9e215ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*6:17295*7-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b6a5b2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2657160.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a441c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "bace305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236, 1007, 1152, 1988]\n",
      "[71, 29, 54, 22, 87, 37, 128]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "32e7439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1812f7",
   "metadata": {},
   "source": [
    "### Phase 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d8c22383",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1aca06a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 138360\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "761c9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "228d3d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ff5116e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9b2f4fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "7773df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.199729, val loss: 0.096518, accuracy: 97.42, time: 14.1429 min\n",
      "----------\n",
      "Epoch 1/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.126209, val loss: 0.077243, accuracy: 97.77, time: 27.3181 min\n",
      "----------\n",
      "Epoch 2/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.101481, val loss: 0.066444, accuracy: 97.94, time: 40.4892 min\n",
      "----------\n",
      "Epoch 3/18, current lr=0.001\n",
      "train loss: 0.086803, val loss: 0.077191, accuracy: 97.81, time: 53.6364 min\n",
      "----------\n",
      "Epoch 4/18, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.074607, val loss: 0.057876, accuracy: 98.13, time: 66.8341 min\n",
      "----------\n",
      "Epoch 5/18, current lr=0.001\n",
      "train loss: 0.064890, val loss: 0.062287, accuracy: 98.01, time: 79.9601 min\n",
      "----------\n",
      "Epoch 6/18, current lr=0.001\n",
      "train loss: 0.057963, val loss: 0.067916, accuracy: 97.70, time: 93.1192 min\n",
      "----------\n",
      "Epoch 7/18, current lr=0.001\n",
      "train loss: 0.051172, val loss: 0.059336, accuracy: 98.19, time: 106.2999 min\n",
      "----------\n",
      "Epoch 8/18, current lr=0.001\n",
      "train loss: 0.045184, val loss: 0.068710, accuracy: 97.79, time: 119.4640 min\n",
      "----------\n",
      "Epoch 9/18, current lr=0.001\n",
      "train loss: 0.039559, val loss: 0.076475, accuracy: 97.67, time: 132.6548 min\n",
      "----------\n",
      "Epoch 10/18, current lr=0.001\n",
      "train loss: 0.034842, val loss: 0.065581, accuracy: 97.95, time: 145.8111 min\n",
      "----------\n",
      "Epoch 11/18, current lr=0.001\n",
      "train loss: 0.029451, val loss: 0.073577, accuracy: 97.94, time: 159.0193 min\n",
      "----------\n",
      "Epoch 12/18, current lr=0.001\n",
      "train loss: 0.025126, val loss: 0.092071, accuracy: 97.12, time: 172.2246 min\n",
      "----------\n",
      "Epoch 13/18, current lr=0.001\n",
      "train loss: 0.021751, val loss: 0.080851, accuracy: 98.04, time: 185.3879 min\n",
      "----------\n",
      "Epoch 14/18, current lr=0.001\n",
      "train loss: 0.019849, val loss: 0.072261, accuracy: 98.01, time: 198.5538 min\n",
      "----------\n",
      "Epoch 15/18, current lr=0.001\n",
      "train loss: 0.017285, val loss: 0.076054, accuracy: 98.17, time: 211.6983 min\n",
      "----------\n",
      "Epoch 16/18, current lr=0.0001\n",
      "train loss: 0.005082, val loss: 0.081560, accuracy: 98.17, time: 224.8605 min\n",
      "----------\n",
      "Epoch 17/18, current lr=0.0001\n",
      "train loss: 0.002616, val loss: 0.088882, accuracy: 98.18, time: 238.0458 min\n",
      "----------\n",
      "Epoch 18/18, current lr=0.0001\n",
      "train loss: 0.001991, val loss: 0.099166, accuracy: 98.25, time: 251.2162 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "af2e08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "9543753d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "29acbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6a0a0732",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9ef4e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*7:17295*8-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e7012ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2647366.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "b7f6effc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d4d4e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236, 1007, 1152, 1988, 609]\n",
      "[71, 29, 54, 22, 87, 37, 128, 88]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "695e407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ac0ffa",
   "metadata": {},
   "source": [
    "### Phase 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b7c201db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "train_folder_dataset.transform = train_transformation\n",
    "train_dl = DataLoader(train_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3b6cbbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 155655\n",
       "    Root location: ../Data/Data_17295/Labeled/"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "84b263c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)\n",
    "original_df = pd.read_csv('../csv/data_172950.csv')\n",
    "tmp = all_imgs[:17295]\n",
    "for i in range(len(tmp)):\n",
    "    idx = int(tmp[i][:-4])\n",
    "    fail_num = str(original_df[original_df['index'] == idx]['failureNum'].values[0])\n",
    "    image_file = str(original_df[original_df['index'] == idx]['index'].values[0]) + '.png'\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(image_file), '../Data/Data_17295/valid/{0}/{1}'.format(fail_num,image_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4bd48050",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dir = '../Data/Data_17295/valid/'\n",
    "valid_folder_dataset = dset.ImageFolder(root=valid_dir)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "valid_folder_dataset.transform = train_transformation\n",
    "valid_dl = DataLoader(valid_folder_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "40f5b964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 17295\n",
       "    Root location: ../Data/Data_17295/valid/"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_folder_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "a9ea8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "cf665d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.187489, val loss: 0.144100, accuracy: 95.83, time: 15.7593 min\n",
      "----------\n",
      "Epoch 1/20, current lr=0.001\n",
      "train loss: 0.116582, val loss: 0.174545, accuracy: 95.61, time: 30.4359 min\n",
      "----------\n",
      "Epoch 2/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.093520, val loss: 0.121273, accuracy: 96.37, time: 45.2595 min\n",
      "----------\n",
      "Epoch 3/20, current lr=0.001\n",
      "train loss: 0.078952, val loss: 0.128090, accuracy: 96.44, time: 60.0077 min\n",
      "----------\n",
      "Epoch 4/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.068578, val loss: 0.101185, accuracy: 96.61, time: 74.7555 min\n",
      "----------\n",
      "Epoch 5/20, current lr=0.001\n",
      "train loss: 0.062099, val loss: 0.103312, accuracy: 96.65, time: 89.4746 min\n",
      "----------\n",
      "Epoch 6/20, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.055929, val loss: 0.084778, accuracy: 97.27, time: 104.2537 min\n",
      "----------\n",
      "Epoch 7/20, current lr=0.001\n",
      "train loss: 0.050121, val loss: 0.100696, accuracy: 97.07, time: 119.0871 min\n",
      "----------\n",
      "Epoch 8/20, current lr=0.001\n",
      "train loss: 0.045244, val loss: 0.101811, accuracy: 97.09, time: 133.9199 min\n",
      "----------\n",
      "Epoch 9/20, current lr=0.001\n",
      "train loss: 0.041097, val loss: 0.101599, accuracy: 97.13, time: 148.7127 min\n",
      "----------\n",
      "Epoch 10/20, current lr=0.001\n",
      "train loss: 0.035373, val loss: 0.096626, accuracy: 96.77, time: 163.5191 min\n",
      "----------\n",
      "Epoch 11/20, current lr=0.001\n",
      "train loss: 0.031800, val loss: 0.105171, accuracy: 97.08, time: 178.2611 min\n",
      "----------\n",
      "Epoch 12/20, current lr=0.001\n",
      "train loss: 0.028133, val loss: 0.115682, accuracy: 96.96, time: 193.0206 min\n",
      "----------\n",
      "Epoch 13/20, current lr=0.001\n",
      "train loss: 0.024799, val loss: 0.100883, accuracy: 96.91, time: 207.8245 min\n",
      "----------\n",
      "Epoch 14/20, current lr=0.001\n",
      "train loss: 0.021419, val loss: 0.117007, accuracy: 96.54, time: 222.5980 min\n",
      "----------\n",
      "Epoch 15/20, current lr=0.001\n",
      "train loss: 0.018948, val loss: 0.138362, accuracy: 97.10, time: 237.6020 min\n",
      "----------\n",
      "Epoch 16/20, current lr=0.001\n",
      "train loss: 0.016612, val loss: 0.138042, accuracy: 96.78, time: 252.6425 min\n",
      "----------\n",
      "Epoch 17/20, current lr=0.001\n",
      "train loss: 0.016401, val loss: 0.199605, accuracy: 96.68, time: 267.5964 min\n",
      "----------\n",
      "Epoch 18/20, current lr=0.0001\n",
      "train loss: 0.005412, val loss: 0.131780, accuracy: 97.09, time: 282.6487 min\n",
      "----------\n",
      "Epoch 19/20, current lr=0.0001\n",
      "train loss: 0.002393, val loss: 0.141766, accuracy: 97.02, time: 298.6225 min\n",
      "----------\n",
      "Epoch 20/20, current lr=0.0001\n",
      "train loss: 0.001787, val loss: 0.158981, accuracy: 97.07, time: 315.6762 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c0d6a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,9):\n",
    "    tmp_label = str(i)\n",
    "    tmp_dir = '../Data/Data_17295/valid/{0}'.format(tmp_label)\n",
    "    tmp_imgs = os.listdir(tmp_dir)\n",
    "    for i in range(len(tmp_imgs)):\n",
    "        shutil.move('../Data/Data_17295/valid/{0}/{1}'.format(tmp_label,tmp_imgs[i]), '../Data/Data_17295/Unlabeled/{0}'.format(tmp_imgs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "cf80bfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                # transforms.Normalize([train_meanR, train_meanG, train_meanB],[train_stdR, train_stdG, train_stdB]),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=train_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset , batch_size=1, shuffle=False)\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "044b0edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "size = len(test_loader.dataset)\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73d20e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)\n",
    "\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    log_outputs = torch.log(pred_list[i][0])\n",
    "    entropy = - torch.sum(pred_list[i][0] * log_outputs)\n",
    "    if entropy> 0.05:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "21347d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label_list = list(df_155655.loc[17295*8:17295*9-1]['failureNum'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0f228919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2658816.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "b42028f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73db99b6",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "1fce8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6454, 5932, 2204, 1236, 1007, 1152, 1988, 609, 804]\n",
      "[71, 29, 54, 22, 87, 37, 128, 88, 158]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "ca820019",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
