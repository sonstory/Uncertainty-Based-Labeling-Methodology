{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc47430d",
   "metadata": {},
   "source": [
    "# Uncertainty Based Cost-Effective Labeling Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e4a716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision\n",
    "import os\n",
    "import natsort\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8858bc",
   "metadata": {},
   "source": [
    "# Device Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ffd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bab7da44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class gpu_setting:\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fc7d5a",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d94721dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BasicBlock.expansion, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n",
    "        )\n",
    "\n",
    "        # identity mapping, input과 output의 feature map size, filter 수가 동일한 경우 사용.\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # projection mapping using 1x1conv\n",
    "        if stride != 1 or in_channels != BasicBlock.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels * BasicBlock.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels * BasicBlock.expansion)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_function = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels * BottleNeck.expansion, kernel_size=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels * BottleNeck.expansion),\n",
    "        )\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        if stride != 1 or in_channels != out_channels * BottleNeck.expansion:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels*BottleNeck.expansion, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels*BottleNeck.expansion)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.residual_function(x) + self.shortcut(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_block, num_classes=9, init_weights=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels=64\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        self.conv2_x = self._make_layer(block, 64, num_block[0], 1)\n",
    "        self.conv3_x = self._make_layer(block, 128, num_block[1], 2)\n",
    "        self.conv4_x = self._make_layer(block, 256, num_block[2], 2)\n",
    "        self.conv5_x = self._make_layer(block, 512, num_block[3], 2)\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "        \n",
    "        # weights inittialization\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * block.expansion\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.conv2_x(output)\n",
    "        x = self.conv3_x(output)\n",
    "        x = self.conv4_x(x)\n",
    "        x = self.conv5_x(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    # define weight initialization function\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "def resnet18():\n",
    "    return ResNet(BasicBlock, [2,2,2,2])\n",
    "\n",
    "def resnet34():\n",
    "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(BottleNeck, [3,4,6,3])\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(BottleNeck, [3, 4, 23, 3])\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(BottleNeck, [3, 8, 36, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ef3dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNetParameters(model, train_dl, valid_dl):\n",
    "    device = gpu_setting.device\n",
    "    model = model.lower()\n",
    "    if model == 'resnet34':\n",
    "        model = resnet34().to(device)\n",
    "    if model == 'resnet50':\n",
    "        model = resnet50().to(device)\n",
    "    if model == 'resnet101':\n",
    "        model = resnet101().to(device)\n",
    "        \n",
    "    loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
    "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
    "    lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)\n",
    "    \n",
    "    # definc the training parameters\n",
    "    params_train = {\n",
    "        'num_epochs':5,\n",
    "        'optimizer':opt,\n",
    "        'loss_func':loss_func,\n",
    "        'train_dl':train_dl, \n",
    "        'val_dl':valid_dl,\n",
    "        'sanity_check':False,\n",
    "        'lr_scheduler':lr_scheduler,\n",
    "        'path2weights':'./trained_model/weights_original_res.pt'\n",
    "    }\n",
    "    return model, params_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742c57c7",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c8797c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(opt):\n",
    "    for param_group in opt.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "def metric_batch(output, target):\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    metric_b = metric_batch(output, target)\n",
    "\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    return loss.item(), metric_b\n",
    "\n",
    "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
    "    running_loss = 0.0\n",
    "    running_metric = 0.0\n",
    "    len_data = len(dataset_dl.dataset)\n",
    "\n",
    "    for xb, yb in dataset_dl:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "        output = model(xb)\n",
    "\n",
    "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
    "\n",
    "        running_loss += loss_b\n",
    "        \n",
    "        if metric_b is not None:\n",
    "            running_metric += metric_b\n",
    "        \n",
    "        if sanity_check is True:\n",
    "            break\n",
    "\n",
    "    loss = running_loss / len_data\n",
    "    metric = running_metric / len_data\n",
    "\n",
    "    return loss, metric\n",
    "\n",
    "def train_val(model, params, epoch):\n",
    "    num_epochs=epoch\n",
    "    loss_func=params[\"loss_func\"]\n",
    "    opt=params[\"optimizer\"]\n",
    "    train_dl=params[\"train_dl\"]\n",
    "    val_dl=params[\"val_dl\"]\n",
    "    sanity_check=params[\"sanity_check\"]\n",
    "    lr_scheduler=params[\"lr_scheduler\"]\n",
    "    path2weights=params[\"path2weights\"]\n",
    "\n",
    "    loss_history = {'train': [], 'val': []}\n",
    "    metric_history = {'train': [], 'val': []}\n",
    "\n",
    "    # # GPU out of memoty error\n",
    "    # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "    best_loss = float('inf')\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        current_lr = get_lr(opt)\n",
    "        print('Epoch {}/{}, current lr={}'.format(epoch, num_epochs-1, current_lr))\n",
    "\n",
    "        model.train()\n",
    "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
    "        loss_history['train'].append(train_loss)\n",
    "        metric_history['train'].append(train_metric)\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
    "        loss_history['val'].append(val_loss)\n",
    "        metric_history['val'].append(val_metric)\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            # best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            torch.save(model.state_dict(), path2weights)\n",
    "            print('Copied best model weights!')\n",
    "            print('Get best val_loss')\n",
    "\n",
    "        lr_scheduler.step(val_loss)\n",
    "\n",
    "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
    "        print('-'*10)\n",
    "\n",
    "    # model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model, loss_history, metric_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2f0a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataSet():\n",
    "    def __init__(self, main_dir, transform, num):\n",
    "        self.main_dir = main_dir\n",
    "        self.transform = transform\n",
    "        self.num = num\n",
    "        all_imgs = os.listdir(main_dir)\n",
    "        self.total_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.total_imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f484b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSubset(Dataset):\n",
    "    def __init__(self,Subset,transform=None):\n",
    "        super(CustomSubset,self).__init__()\n",
    "        self.Subset=Subset\n",
    "        self.indices=Subset.indices\n",
    "        self.transform=transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Subset)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img,label=self.Subset[idx]\n",
    "        if self.transform is not None:\n",
    "            img=self.transform(img)\n",
    "        return img,label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc13659",
   "metadata": {},
   "source": [
    "# csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb095259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_155655 = pd.read_csv('../csv/data_155655.csv')\n",
    "label = pd.read_csv('../csv/data_172950.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb49d96",
   "metadata": {},
   "source": [
    "# Phase 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84403059",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4b993947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial train data(17,295)\n",
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60047b3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13836 3459\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "714b7dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f16799d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c82bb46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.364726, val loss: 0.355461, accuracy: 91.93, time: 1.5254 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.229135, val loss: 0.206227, accuracy: 93.52, time: 2.3221 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "train loss: 0.203866, val loss: 0.255207, accuracy: 92.28, time: 3.1225 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.182893, val loss: 0.309487, accuracy: 91.12, time: 3.9249 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.167609, val loss: 0.222912, accuracy: 93.78, time: 4.7345 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253a5a5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba7077",
   "metadata": {},
   "source": [
    "### Set 1 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "779a54b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c373b21",
   "metadata": {},
   "source": [
    "### Set 1 data predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "48e00f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "579b812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3076a41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2810a532",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fc98f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf72da18",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fb2764f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 3152563.57it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engineer_label_count = []\n",
    "wrong_cnt_list = []\n",
    "real_label_list = list(df_155655.loc[:17294]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cb742030",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59df7a7",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "897cfae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130]\n",
      "[46]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42d33d",
   "metadata": {},
   "source": [
    "## Append Set 1 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3d655de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e23b78",
   "metadata": {},
   "source": [
    "# Phase 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc020a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "34babf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "96bff746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27672 6918\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "683601dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e93ffc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3e2b7ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.344499, val loss: 0.325057, accuracy: 91.44, time: 1.6534 min\n",
      "----------\n",
      "Epoch 1/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.209329, val loss: 0.239570, accuracy: 93.21, time: 3.2910 min\n",
      "----------\n",
      "Epoch 2/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.172744, val loss: 0.149862, accuracy: 94.84, time: 4.9431 min\n",
      "----------\n",
      "Epoch 3/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.149204, val loss: 0.138496, accuracy: 95.79, time: 6.5751 min\n",
      "----------\n",
      "Epoch 4/6, current lr=0.001\n",
      "train loss: 0.134793, val loss: 0.161303, accuracy: 95.33, time: 8.2285 min\n",
      "----------\n",
      "Epoch 5/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.119900, val loss: 0.134303, accuracy: 95.94, time: 9.8890 min\n",
      "----------\n",
      "Epoch 6/6, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.110187, val loss: 0.113360, accuracy: 96.52, time: 11.5135 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44df4418",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229fada1",
   "metadata": {},
   "source": [
    "### Set 2 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf5d25fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91bbb596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dff395",
   "metadata": {},
   "source": [
    "### Set 2 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2b69fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0bb5d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1b45e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41bcb7f",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e0ece346",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fe391",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "76133f75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892133.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*1:17295*2-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "787d4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a4bec",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ea0f6229",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998]\n",
      "[46, 41]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300937c0",
   "metadata": {},
   "source": [
    "## Append Set 2 Data to Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "305474b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626030f",
   "metadata": {},
   "source": [
    "# Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0bbc79",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ce2eef8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70496597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41508 10377\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5a1223db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f05dcb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d418a46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.341639, val loss: 0.236236, accuracy: 92.72, time: 2.4815 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.200848, val loss: 0.202983, accuracy: 93.87, time: 4.9023 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.168646, val loss: 0.163759, accuracy: 94.99, time: 7.3422 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.140114, val loss: 0.168486, accuracy: 94.57, time: 9.7998 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.125964, val loss: 0.225973, accuracy: 93.72, time: 12.2306 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f2920",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5063921",
   "metadata": {},
   "source": [
    "### Set 3 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "1e28fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "390a3906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3463439",
   "metadata": {},
   "source": [
    "### Set 3 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58af0309",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e034eb7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a443db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12766a9e",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f6dd9ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a5f62a",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "a8b4aa34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2478999.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*2:17295*3-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "951ece9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafeed49",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "68a26d8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353]\n",
      "[46, 41, 19]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc56204",
   "metadata": {},
   "source": [
    "## Append Set 3 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "17703ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d71d1f",
   "metadata": {},
   "source": [
    "# Phase 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a636e9",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3008d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6cef9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55344 13836\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75b51cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a7b7cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "71774200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.289353, val loss: 0.212728, accuracy: 93.40, time: 3.3250 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.185630, val loss: 0.134281, accuracy: 95.23, time: 6.6139 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "train loss: 0.155860, val loss: 0.144121, accuracy: 95.46, time: 9.9798 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.135188, val loss: 0.125400, accuracy: 96.18, time: 13.2296 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.120916, val loss: 0.140377, accuracy: 95.58, time: 16.5038 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19fded5",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e72e27",
   "metadata": {},
   "source": [
    "### Set 4 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "5812e511",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "22282948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cdf469d",
   "metadata": {},
   "source": [
    "### Set 4  Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "eba38c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "9b31e905",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3602316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653d05f6",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f67d2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd50df2",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "77b217da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892248.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*3:17295*4-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "23a5c1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b425768c",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f50425bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112]\n",
      "[46, 41, 19, 36]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68511d95",
   "metadata": {},
   "source": [
    "## Append Set 4 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "0da2e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be31b2f",
   "metadata": {},
   "source": [
    "# Phase 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d0b4fb",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "45c791c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "6dfd2072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69180 17295\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "4c5ec60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dbf0f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f104f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.256166, val loss: 0.148044, accuracy: 95.27, time: 4.1261 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "train loss: 0.156794, val loss: 0.161723, accuracy: 95.17, time: 10.8184 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.136792, val loss: 0.113433, accuracy: 96.31, time: 15.3467 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.115320, val loss: 0.134220, accuracy: 96.11, time: 19.4349 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.099573, val loss: 0.160896, accuracy: 95.72, time: 23.4916 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79da80ac",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adf669f",
   "metadata": {},
   "source": [
    "### Set 5 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "89bf891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "ec196ddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90dcac",
   "metadata": {},
   "source": [
    "### Set 5 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2b662194",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "b2315a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "759a44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88601ef7",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "2e69863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3287d536",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a9e4791c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2891326.39it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*4:17295*5-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b842c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac424516",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "7cb79110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112, 2522]\n",
      "[46, 41, 19, 36, 45]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a81d9a1",
   "metadata": {},
   "source": [
    "## Append Set 5 to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cc060d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf453024",
   "metadata": {},
   "source": [
    "# Phase 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e872a0b7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7c833e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "88750564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83016 20754\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1a28a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "37993798",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "208f70dc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.246027, val loss: 0.177681, accuracy: 94.55, time: 4.8952 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "train loss: 0.153302, val loss: 0.464455, accuracy: 86.83, time: 10.1070 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.128450, val loss: 0.117121, accuracy: 96.42, time: 15.0669 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.111389, val loss: 0.125228, accuracy: 96.46, time: 19.7835 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.098176, val loss: 0.097652, accuracy: 97.11, time: 24.7524 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a8ae8",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89384f",
   "metadata": {},
   "source": [
    "### Set 6 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a87c18a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8fe80841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a507e",
   "metadata": {},
   "source": [
    "### Set 6 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f865ead1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c6125408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17295"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "70f11204",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d66b12",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d2f06ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818dc4b",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c186b886",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892133.31it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*5:17295*6-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c48c0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee012fb7",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "057f6c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112, 2522, 1834]\n",
      "[46, 41, 19, 36, 45, 74]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aca9c31",
   "metadata": {},
   "source": [
    "## Appned Set 6 Data to Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b3d1c66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4b8dc5",
   "metadata": {},
   "source": [
    "# Phase 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401221aa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "45a11ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "615a8646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96852 24213\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac6e38a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4f930a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cfcbec21",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.220845, val loss: 0.153382, accuracy: 95.22, time: 6.6367 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "train loss: 0.138895, val loss: 0.194730, accuracy: 93.84, time: 13.1283 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.113683, val loss: 0.105405, accuracy: 96.60, time: 19.5822 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.099146, val loss: 0.080264, accuracy: 97.42, time: 25.2131 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.084296, val loss: 0.088859, accuracy: 97.09, time: 30.8535 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b2d17b",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de130196",
   "metadata": {},
   "source": [
    "### Set 7 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "af490315",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50577300",
   "metadata": {},
   "source": [
    "### Set 7 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "00b3ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "e6f6a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4503f015",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4d92e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "fe7ea1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2478999.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*6:17295*7-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "31af1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf00145",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "5bacc46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112, 2522, 1834, 2644]\n",
      "[46, 41, 19, 36, 45, 74, 70]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a910aee",
   "metadata": {},
   "source": [
    "## Append Set 7 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f2647f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32734c9",
   "metadata": {},
   "source": [
    "# Phase 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9f5c4f",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8063d9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "2cb6c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110688 27672\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "2763e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ed21319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ad416be3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.219998, val loss: 0.165572, accuracy: 95.23, time: 7.1483 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.140101, val loss: 0.114836, accuracy: 96.12, time: 14.1868 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.116261, val loss: 0.110472, accuracy: 96.52, time: 20.6697 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.096622, val loss: 0.087698, accuracy: 97.12, time: 27.3044 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "train loss: 0.084356, val loss: 0.104829, accuracy: 96.70, time: 33.9670 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c7fc0",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b72b4a",
   "metadata": {},
   "source": [
    "### Set 8 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "af29d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469fb076",
   "metadata": {},
   "source": [
    "### Set 8 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "bb8708cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "cb9e6228",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abaf71cc",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e10cf655",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf5b980",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "75018c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2665263.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*7:17295*8-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "eff48fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51584ae6",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "20f03228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112, 2522, 1834, 2644, 1792]\n",
      "[46, 41, 19, 36, 45, 74, 70, 18]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa4ab6d",
   "metadata": {},
   "source": [
    "## Add Set 8 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "3a6a89e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9975304c",
   "metadata": {},
   "source": [
    "# Phase 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d70ac5",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b54a6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/Data_17295/Labeled/'\n",
    "train_folder_dataset = dset.ImageFolder(root=train_dir)\n",
    "\n",
    "# train & valid split\n",
    "train_data_len = int(len(train_folder_dataset)*0.8)\n",
    "valid_data_len = len(train_folder_dataset) - train_data_len\n",
    "train_data, valid_data = random_split(train_folder_dataset, [train_data_len, valid_data_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "bc3d2f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124524 31131\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data), len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "6ead8df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "\n",
    "train_data = CustomSubset(train_data, train_transformation)\n",
    "valid_data = CustomSubset(valid_data, train_transformation)\n",
    "\n",
    "train_dl = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "eb25ba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, params_train = ResNetParameters('resnet50', train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "3a17dc7d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.201428, val loss: 0.161952, accuracy: 95.04, time: 7.1705 min\n",
      "----------\n",
      "Epoch 1/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.126477, val loss: 0.124955, accuracy: 96.04, time: 14.5604 min\n",
      "----------\n",
      "Epoch 2/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.104695, val loss: 0.102634, accuracy: 96.57, time: 22.0511 min\n",
      "----------\n",
      "Epoch 3/4, current lr=0.001\n",
      "train loss: 0.089598, val loss: 0.137079, accuracy: 95.85, time: 29.5040 min\n",
      "----------\n",
      "Epoch 4/4, current lr=0.001\n",
      "Copied best model weights!\n",
      "Get best val_loss\n",
      "train loss: 0.077900, val loss: 0.099528, accuracy: 96.82, time: 37.0014 min\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "model, loss_hist, metric_hist = train_val(model, params_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba512ca2",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd90189f",
   "metadata": {},
   "source": [
    "### Set 9 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "83117b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "test_dir = '../Data/Data_17295/Unlabeled/'\n",
    "test_transformation = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),\n",
    "                ])\n",
    "my_dataset = CustomDataSet(test_dir, transform=test_transformation, num=0)\n",
    "test_loader = DataLoader(my_dataset, shuffle=False)\n",
    "\n",
    "all_imgs = os.listdir(test_dir)\n",
    "all_imgs = natsort.natsorted(all_imgs)[17295*num:17295*(num+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bfb75",
   "metadata": {},
   "source": [
    "### Set 9 Data Predict & Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "af7d754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list =[]\n",
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "with torch.no_grad():\n",
    "    for X in test_loader:\n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        sft = torch.nn.functional.softmax(pred, dim=1)\n",
    "        pred_list.append(sft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "8352085e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = []\n",
    "for i in range(0,17295):\n",
    "    max_list.append(float(pred_list[i][0].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1434ea",
   "metadata": {},
   "source": [
    "### Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e1b4c951",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "label_list = []\n",
    "img_folder = natsort.natsorted(all_imgs)\n",
    "\n",
    "for i in range(0,17295):\n",
    "    if pred_list[i][0].max()<0.99:\n",
    "        idx = int(img_folder[i][:-4])\n",
    "        engineerlabel = int(label[label['index']==idx]['failureNum'])\n",
    "        label_list.append(engineerlabel)\n",
    "        cnt = cnt + 1\n",
    "    else:\n",
    "        label_list.append(int(pred_list[i][0].argmax()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa18aa",
   "metadata": {},
   "source": [
    "### Mislabelings & Engineer Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "b4b8a4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 17295/17295 [00:00<00:00, 2892363.94it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label_list = list(df_155655.loc[17295*8:17295*9-1]['failureNum'].values)\n",
    "wrong_cnt = 0\n",
    "for i in tqdm(range(0,17295)):\n",
    "    if label_list[i] != real_label_list[i]:\n",
    "        wrong_cnt = wrong_cnt + 1\n",
    "        \n",
    "wrong_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "a0d3d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "engineer_label_count.append(cnt)\n",
    "wrong_cnt_list.append(wrong_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009150cb",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "af3be60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6130, 4998, 5353, 2112, 2522, 1834, 2644, 1792, 1947]\n",
      "[46, 41, 19, 36, 45, 74, 70, 18, 90]\n"
     ]
    }
   ],
   "source": [
    "print(engineer_label_count)\n",
    "print(wrong_cnt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6e1da",
   "metadata": {},
   "source": [
    "## Add Set 9 Data to Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "86d04d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,17295):\n",
    "    shutil.move('../Data/Data_17295/Unlabeled/{0}'.format(img_folder[i]),'../Data/Data_17295/Labeled/{0}/{1}'.format(label_list[i],img_folder[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0a65db",
   "metadata": {},
   "source": [
    "# Final Result\n",
    "- Mislabelings : 439 / 155,655(0.28%)\n",
    "    - per phase : 46 / 41 / 19 / 36 / 45 / 74 / 70 / 18 / 90\n",
    "- Engineer Cost : 29,332 / 155,655(18.84%)\n",
    "    - per phase : 6130 / 4998 / 5353 / 2112 / 2522 / 1834 / 2644 / 1792 / 1947"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "408px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
